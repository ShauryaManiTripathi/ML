{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age  MonthlyCharges  Tenure  Contract_Month-to-month  Contract_One year  \\\n",
      "0     56          148.71      43                     True              False   \n",
      "1     69           38.21      70                     True              False   \n",
      "2     46           87.38      39                     True              False   \n",
      "3     32          134.06      56                    False              False   \n",
      "4     60          116.30      63                    False              False   \n",
      "..   ...             ...     ...                      ...                ...   \n",
      "602   27          116.40      33                    False              False   \n",
      "603   45           75.40      21                    False               True   \n",
      "604   52          133.20      18                     True              False   \n",
      "605   41           96.80      27                    False              False   \n",
      "606   55          121.00      31                    False               True   \n",
      "\n",
      "     Contract_Two year  \n",
      "0                False  \n",
      "1                False  \n",
      "2                False  \n",
      "3                 True  \n",
      "4                 True  \n",
      "..                 ...  \n",
      "602               True  \n",
      "603              False  \n",
      "604              False  \n",
      "605               True  \n",
      "606              False  \n",
      "\n",
      "[607 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('churn_data.csv')\n",
    "\n",
    "# Prepare the features and target\n",
    "X = data[['Age', 'MonthlyCharges', 'Tenure']]\n",
    "y = data['Churn']\n",
    "\n",
    "# One-hot encode the ContractType\n",
    "contract_type_dummies = pd.get_dummies(data['ContractType'], prefix='Contract')\n",
    "X = pd.concat([X, contract_type_dummies], axis=1)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age  MonthlyCharges  Tenure  Contract_Month-to-month  Contract_One year  \\\n",
      "0     56          148.71      43                     True              False   \n",
      "1     69           38.21      70                     True              False   \n",
      "2     46           87.38      39                     True              False   \n",
      "3     32          134.06      56                    False              False   \n",
      "4     60          116.30      63                    False              False   \n",
      "..   ...             ...     ...                      ...                ...   \n",
      "602   27          116.40      33                    False              False   \n",
      "603   45           75.40      21                    False               True   \n",
      "604   52          133.20      18                     True              False   \n",
      "605   41           96.80      27                    False              False   \n",
      "606   55          121.00      31                    False               True   \n",
      "\n",
      "     Contract_Two year  \n",
      "0                False  \n",
      "1                False  \n",
      "2                False  \n",
      "3                 True  \n",
      "4                 True  \n",
      "..                 ...  \n",
      "602               True  \n",
      "603              False  \n",
      "604              False  \n",
      "605               True  \n",
      "606              False  \n",
      "\n",
      "[607 rows x 6 columns]\n",
      "          Age  MonthlyCharges    Tenure  Contract_Month-to-month  \\\n",
      "0    0.886703        1.872813  0.772488                     True   \n",
      "1    1.812107       -2.051478  2.604394                     True   \n",
      "2    0.174854       -0.305257  0.501094                     True   \n",
      "3   -0.821734        1.352533  1.654517                    False   \n",
      "4    1.171443        0.721806  2.129455                    False   \n",
      "..        ...             ...       ...                      ...   \n",
      "602 -1.177658        0.725357  0.094004                    False   \n",
      "603  0.103670       -0.730714 -0.720176                    False   \n",
      "604  0.601964        1.321991 -0.923721                     True   \n",
      "605 -0.181070        0.029284 -0.313086                    False   \n",
      "606  0.815518        0.888721 -0.041693                    False   \n",
      "\n",
      "     Contract_One year  Contract_Two year  \n",
      "0                False              False  \n",
      "1                False              False  \n",
      "2                False              False  \n",
      "3                False               True  \n",
      "4                False               True  \n",
      "..                 ...                ...  \n",
      "602              False               True  \n",
      "603               True              False  \n",
      "604              False              False  \n",
      "605              False               True  \n",
      "606               True              False  \n",
      "\n",
      "[607 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Normalize continuous features\n",
    "def normalize(X):\n",
    "    return (X - X.mean()) / X.std()\n",
    "\n",
    "X_normalized = X.copy()\n",
    "print(X_normalized)\n",
    "X_normalized[['Age', 'MonthlyCharges', 'Tenure']] = normalize(X[['Age', 'MonthlyCharges', 'Tenure']])\n",
    "print(X_normalized)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X_normalized = X_normalized.values.astype(\"float\")\n",
    "y = y.values.astype(\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid function\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# Cost function\n",
    "def compute_cost(X, y, theta):\n",
    "    m = len(y)\n",
    "    h = sigmoid(X @ theta)\n",
    "    cost = (-1/m) * np.sum(y * np.log(h) + (1-y) * np.log(1-h))\n",
    "    return cost\n",
    "\n",
    "# Gradient descent\n",
    "def gradient_descent(X, y, theta, alpha, num_iters):\n",
    "    m = len(y)\n",
    "    J_history = []\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        h = sigmoid(X @ theta)\n",
    "        gradient = (1/m) * X.T @ (h - y)\n",
    "        theta = theta - alpha * gradient\n",
    "        J_history.append(compute_cost(X, y, theta))\n",
    "    \n",
    "    return theta, J_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add bias term to X\n",
    "X_normalized = np.c_[np.ones((X_normalized.shape[0], 1)), X_normalized]\n",
    "\n",
    "# Initialize parameters\n",
    "theta = np.random.randn(X_normalized.shape[1])\n",
    "\n",
    "# Set hyperparameters\n",
    "alpha = 0.01\n",
    "num_iters = 1000\n",
    "\n",
    "# Run gradient descent\n",
    "theta_optimal, J_history = gradient_descent(X_normalized, y, theta, alpha, num_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict function\n",
    "def predict(X, theta):\n",
    "    return sigmoid(X @ theta) >= 0.5\n",
    "\n",
    "# Evaluate model\n",
    "def evaluate_model(X, y, theta):\n",
    "    y_pred = predict(X, theta)\n",
    "    accuracy = np.mean(y_pred == y)\n",
    "    \n",
    "    TP = np.sum((y == 1) & (y_pred == 1))\n",
    "    TN = np.sum((y == 0) & (y_pred == 0))\n",
    "    FP = np.sum((y == 0) & (y_pred == 1))\n",
    "    FN = np.sum((y == 1) & (y_pred == 0))\n",
    "    \n",
    "    confusion_matrix = np.array([[TN, FP], [FN, TP]])\n",
    "    \n",
    "    return accuracy, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform k-fold cross-validation\n",
    "def cross_validation(X, y, k=5):\n",
    "    fold_size = len(X) // k\n",
    "    accuracies = []\n",
    "    confusion_matrices = []\n",
    "    \n",
    "    for i in range(k):\n",
    "        start = i * fold_size\n",
    "        end = (i + 1) * fold_size\n",
    "        \n",
    "        X_test = X[start:end]\n",
    "        y_test = y[start:end]\n",
    "        X_train = np.concatenate([X[:start], X[end:]])\n",
    "        y_train = np.concatenate([y[:start], y[end:]])\n",
    "        \n",
    "        theta = np.random.randn(X.shape[1])\n",
    "        theta_optimal, _ = gradient_descent(X_train, y_train, theta, alpha, num_iters)\n",
    "        \n",
    "        accuracy, confusion_matrix = evaluate_model(X_test, y_test, theta_optimal)\n",
    "        accuracies.append(accuracy)\n",
    "        confusion_matrices.append(confusion_matrix)\n",
    "    \n",
    "    return np.mean(accuracies), np.mean(confusion_matrices, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy: 0.7950\n",
      "Average confusion matrix:\n",
      "[[68.  11.2]\n",
      " [13.6 28.2]]\n"
     ]
    }
   ],
   "source": [
    "# Perform cross-validation\n",
    "cv_accuracy, cv_confusion_matrix = cross_validation(X_normalized, y)\n",
    "print(f\"Cross-validation accuracy: {cv_accuracy:.4f}\")\n",
    "print(\"Average confusion matrix:\")\n",
    "print(cv_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final model accuracy: 0.8254\n",
      "Final confusion matrix:\n",
      "[[362  36]\n",
      " [ 70 139]]\n"
     ]
    }
   ],
   "source": [
    "# Train final model on entire dataset\n",
    "theta_final, _ = gradient_descent(X_normalized, y, theta, alpha, num_iters)\n",
    "\n",
    "# Final evaluation\n",
    "final_accuracy, final_confusion_matrix = evaluate_model(X_normalized, y, theta_final)\n",
    "print(f\"\\nFinal model accuracy: {final_accuracy:.4f}\")\n",
    "print(\"Final confusion matrix:\")\n",
    "print(final_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimal parameters:\n",
      "Bias: 0.1035\n",
      "Age: -0.0898\n",
      "MonthlyCharges: 0.0982\n",
      "Tenure: -0.7713\n",
      "Contract_Month-to-month: 0.0119\n",
      "Contract_One year: -1.3742\n",
      "Contract_Two year: -1.1386\n"
     ]
    }
   ],
   "source": [
    "# Print optimal parameters\n",
    "print(\"\\nOptimal parameters:\")\n",
    "feature_names = ['Bias'] + list(X.columns)\n",
    "for name, param in zip(feature_names, theta_final):\n",
    "    print(f\"{name}: {param:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy: 0.7190\n",
      "Average confusion matrix:\n",
      "[[74.2  3.6  1.4]\n",
      " [ 8.6  9.4  2.8]\n",
      " [ 8.8  8.8  3.4]]\n",
      "\n",
      "Final model accuracy: 0.7035\n",
      "Final confusion matrix:\n",
      "[[375   6  17]\n",
      " [ 48  12  44]\n",
      " [ 49  16  40]]\n",
      "\n",
      "Optimal parameters:\n",
      "\n",
      "Class: No Churn\n",
      "Bias: 0.1668\n",
      "Age: 0.6699\n",
      "MonthlyCharges: -0.0792\n",
      "Tenure: 0.6008\n",
      "Contract_Month-to-month: -1.2585\n",
      "Contract_One year: 0.7620\n",
      "Contract_Two year: 0.4435\n",
      "\n",
      "Class: Voluntary Churn\n",
      "Bias: -0.9904\n",
      "Age: 0.0658\n",
      "MonthlyCharges: 0.0571\n",
      "Tenure: -0.2728\n",
      "Contract_Month-to-month: -0.7032\n",
      "Contract_One year: -0.3765\n",
      "Contract_Two year: -0.1479\n",
      "\n",
      "Class: Involuntary Churn\n",
      "Bias: -1.3255\n",
      "Age: 0.1985\n",
      "MonthlyCharges: -0.3790\n",
      "Tenure: -0.4960\n",
      "Contract_Month-to-month: -0.1959\n",
      "Contract_One year: -0.8239\n",
      "Contract_Two year: -1.4422\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('churn_data.csv')\n",
    "\n",
    "# Create a new column 'ChurnType' based on 'Churn'\n",
    "def assign_churn_type(row):\n",
    "    if row['Churn'] == 0:\n",
    "        return 0  # No Churn\n",
    "    else:\n",
    "        # Randomly assign Voluntary (1) or Involuntary (2) Churn\n",
    "        return np.random.choice([1, 2])\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Apply the function to create the new column\n",
    "data['ChurnType'] = data.apply(assign_churn_type, axis=1)\n",
    "\n",
    "# Prepare the features and target\n",
    "X = data[['Age', 'MonthlyCharges', 'Tenure']]\n",
    "y = data['ChurnType']\n",
    "\n",
    "# One-hot encode the ContractType\n",
    "contract_type_dummies = pd.get_dummies(data['ContractType'], prefix='Contract')\n",
    "X = pd.concat([X, contract_type_dummies], axis=1)\n",
    "\n",
    "# Normalize continuous features\n",
    "def normalize(X):\n",
    "    return (X - X.mean()) / X.std()\n",
    "\n",
    "X_normalized = X.copy()\n",
    "X_normalized[['Age', 'MonthlyCharges', 'Tenure']] = normalize(X[['Age', 'MonthlyCharges', 'Tenure']])\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X_normalized = X_normalized.values.astype(\"float\")\n",
    "y = y.values.astype(\"int\")\n",
    "\n",
    "# Add bias term to X\n",
    "X_normalized = np.c_[np.ones((X_normalized.shape[0], 1)), X_normalized]\n",
    "\n",
    "# Softmax function\n",
    "def softmax(z):\n",
    "    exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
    "    return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
    "\n",
    "# Cost function\n",
    "def compute_cost(X, y, theta):\n",
    "    m = len(y)\n",
    "    h = softmax(X @ theta)\n",
    "    cost = (-1/m) * np.sum(np.eye(3)[y] * np.log(h))\n",
    "    return cost\n",
    "\n",
    "# Gradient descent\n",
    "def gradient_descent(X, y, theta, alpha, num_iters):\n",
    "    m = len(y)\n",
    "    J_history = []\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        h = softmax(X @ theta)\n",
    "        gradient = (1/m) * X.T @ (h - np.eye(3)[y])\n",
    "        theta = theta - alpha * gradient\n",
    "        J_history.append(compute_cost(X, y, theta))\n",
    "    \n",
    "    return theta, J_history\n",
    "\n",
    "# Predict function\n",
    "def predict(X, theta):\n",
    "    return np.argmax(softmax(X @ theta), axis=1)\n",
    "\n",
    "# Evaluate model\n",
    "def evaluate_model(X, y, theta):\n",
    "    y_pred = predict(X, theta)\n",
    "    accuracy = np.mean(y_pred == y)\n",
    "    \n",
    "    confusion_matrix = np.zeros((3, 3), dtype=int)\n",
    "    for true, pred in zip(y, y_pred):\n",
    "        confusion_matrix[true, pred] += 1\n",
    "    \n",
    "    return accuracy, confusion_matrix\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "def cross_validation(X, y, k=5):\n",
    "    fold_size = len(X) // k\n",
    "    accuracies = []\n",
    "    confusion_matrices = []\n",
    "    \n",
    "    for i in range(k):\n",
    "        start = i * fold_size\n",
    "        end = (i + 1) * fold_size\n",
    "        \n",
    "        X_test = X[start:end]\n",
    "        y_test = y[start:end]\n",
    "        X_train = np.concatenate([X[:start], X[end:]])\n",
    "        y_train = np.concatenate([y[:start], y[end:]])\n",
    "        \n",
    "        theta = np.random.randn(X.shape[1], 3)\n",
    "        theta_optimal, _ = gradient_descent(X_train, y_train, theta, alpha, num_iters)\n",
    "        \n",
    "        accuracy, confusion_matrix = evaluate_model(X_test, y_test, theta_optimal)\n",
    "        accuracies.append(accuracy)\n",
    "        confusion_matrices.append(confusion_matrix)\n",
    "    \n",
    "    return np.mean(accuracies), np.mean(confusion_matrices, axis=0)\n",
    "\n",
    "# Set hyperparameters\n",
    "alpha = 0.01\n",
    "num_iters = 1000\n",
    "\n",
    "# Initialize parameters\n",
    "theta = np.random.randn(X_normalized.shape[1], 3)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_accuracy, cv_confusion_matrix = cross_validation(X_normalized, y)\n",
    "print(f\"Cross-validation accuracy: {cv_accuracy:.4f}\")\n",
    "print(\"Average confusion matrix:\")\n",
    "print(cv_confusion_matrix)\n",
    "\n",
    "# Train final model on entire dataset\n",
    "theta_final, _ = gradient_descent(X_normalized, y, theta, alpha, num_iters)\n",
    "\n",
    "# Final evaluation\n",
    "final_accuracy, final_confusion_matrix = evaluate_model(X_normalized, y, theta_final)\n",
    "print(f\"\\nFinal model accuracy: {final_accuracy:.4f}\")\n",
    "print(\"Final confusion matrix:\")\n",
    "print(final_confusion_matrix)\n",
    "\n",
    "# Print optimal parameters\n",
    "print(\"\\nOptimal parameters:\")\n",
    "feature_names = ['Bias'] + list(X.columns)\n",
    "for i, class_name in enumerate(['No Churn', 'Voluntary Churn', 'Involuntary Churn']):\n",
    "    print(f\"\\nClass: {class_name}\")\n",
    "    for name, param in zip(feature_names, theta_final[:, i]):\n",
    "        print(f\"{name}: {param:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
